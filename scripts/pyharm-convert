#!/usr/bin/env python3

__license__ = """
 File: pyharm-convert
 
 BSD 3-Clause License
 
 Copyright (c) 2020-2023, Ben Prather and AFD Group at UIUC
 All rights reserved.
 
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are met:
 
 1. Redistributions of source code must retain the above copyright notice, this
    list of conditions and the following disclaimer.
 
 2. Redistributions in binary form must reproduce the above copyright notice,
    this list of conditions and the following disclaimer in the documentation
    and/or other materials provided with the distribution.
 
 3. Neither the name of the copyright holder nor the names of its
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.
 
 THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import os
import psutil
import click
import multiprocessing
from functools import partial

import numpy as np

import pyharm
from pyharm.parallel import map_parallel

def convert_file(name_pair, double=False, to_restart=False, resume=False):
    """Read a single file of some type, and write it as Illinois HDF5 format"""
    fname, outfname = name_pair
    #print("Converting {} -> {}".format(fname, outfname), file=sys.stderr)
    if not (resume and os.path.exists(outfname)):
        dump = pyharm.load_dump(fname, use_grid_cache=False)
        if to_restart:
            # TODO complain a lot if dump is not in double!!
            pyharm.io.iharm3d_restart.write_restart(dump, outfname)
        else:
            pyharm.io.iharm3d.write_dump(dump, outfname, astype=(np.float32, np.float64)[double])
        del dump

@click.command()
@click.argument('files', nargs=-1)
# Common options
@click.option('-p', '--path', default=None, help="Output filepath prefix, e.g. dumps/.")
@click.option('-o', '--outfile', default=None, help="Output filename, if converting a single dump.")
@click.option('-r', '--resume', is_flag=True, help="Only convert files not already present in the output directory")
@click.option('--double', is_flag=True, help="Read/write in double precision")
@click.option('--to_restart', is_flag=True, help="Write an iharm3d restart file suitable for resizing. Implies --double.")
@click.option('-nt', '--nthreads', default=None, help="Number of parallel conversions -- defaults to min(nprocs, 64)")
@click.option('-d', '--debug', is_flag=True, help="Serial operation for debugging")
def convert(files, path, outfile, double, to_restart, resume, nthreads, debug):
    """Convert a file from KHARMA format (or any readable format) into iharm3d/Illinois HDF5 format
    (and only this format, as pyharm cannot write other file formats).

    Tries to preserve as much as possible of the original data, but not everything may transfer:
    see pyharm/io/iharm3d.py for details of the file writer.

    Defaults to writing output to the same directory as input files, optionally output to a different
    directory with '-p'. Adds a '.h5' file extension in place of KHARMA's .phdf, or additionally to other
    formats.

    Usage: convert.py FILE1 [FILE2 FILE3]

    Note on parallelization: fewer threads may be much faster on some machines (even supercomputer nodes)
    due to contention.  Play arount with -nt to find what's fastest.  There is a hard limit of 32 threads,
    as no machine in existence gracefully handles more than that number of simultaneous file reads to one node.
    """
    if path is not None:
        # Make the path and prepend it to new filenames
        os.makedirs(path, exist_ok=True)
        outfiles = [os.path.join(path, f.split("/")[-1].replace(".phdf", "")+".h5") for f in files]
    elif outfile is not None:
        # Out list of one
        outfiles = [outfile]
    else:
        # Place new files alongside the old
        outfiles = [f.replace(".phdf", "").replace(".rhdf","")+".h5" for f in files]

    # TODO if resume, take out existing files *here*

    if debug:
        for file, outfile in zip(files, outfiles):
            convert_file((file, outfile), double, to_restart)
    else:
        if nthreads is None:
            nthreads = min(min(psutil.cpu_count(), len(files)), 32)
        else:
            nthreads = int(nthreads)

        convert_func = partial(convert_file, double=double, to_restart=to_restart, resume=resume)

        print("Converting {} files with {} threads".format(len(files), nthreads))
        map_parallel(convert_func, zip(files, outfiles), nprocs=nthreads)
        print("Converted all files.")

if __name__ == "__main__":
    convert()
